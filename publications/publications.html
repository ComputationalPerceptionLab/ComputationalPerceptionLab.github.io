<!doctype html>
<html>

<head>
    <meta charset="UTF-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
		<meta name="HandheldFriendly" content="True">
	<meta name="MobileOptimized" content="320">
	<meta name="viewport" content="user-scalable=yes">

​	
    <title>Computational Perception Lab</title>
    <link rel="stylesheet" href="../css/index.css">
    <link rel="stylesheet" href="./publications.css">
</head>

<body>

	<div class="header">
	    <span class="header_logo"><a href="index.html"><img src="../images/logo.png" height="60 px" title="Computational Perception Lab" /></a></span>
	    <span class="header_a">
	        <a href="../index.html" id="home">Home</a>
	        <span></span>
	        <a href="#">Members</a>
	        <span></span>
	        <a href="../research/research.html">Research</a>
	        <span></span>
	        <a href="../publications/publications.html">Publications</a>
	        <span></span>
	    </span>
	</div>



    <div>
        <div style="height: 80px;"></div>
    
        <div>
            <h1 class="publictions_title">Publications</h1>
        </div>


        <div class="publictions_display">
			
			
			
			<div class="box3">
                <div class="publictions_img">
                    <img src="./assert/nc.png">
                </div>
                <div class="publictions_text">
                    <p>Nature Communication</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Trilobite-inspired neural nanophotonic light-field camera with extreme depth-of-field</h3>
                    <p class="publictions_indentation">Inspired by the optical structure of trilobite eyes, we demonstrate a nanophotonic light-field camera incorporating a spin-multiplexed bifocal metalens array capable of capturing high-resolution light-field images over a record depth-of-field ranging from centimeter to kilometer scale, simultaneously enabling macro and telephoto modes in a snapshot imaging. </p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href=""
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>		
			
			
			
			
			 <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/fisherToF.png">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2022</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Fisher Information Guidance for Learned Time-of-Flight Imaging</h3>
                    <p class="publictions_indentation">In this paper, we propose a Fisher-information guided framework to jointly optimize the coding functions (light modulation and sensor demodulation functions) and the reconstruction network of iToF imaging, with the supervision of the proposed discriminative fisher loss.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href=""
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
			
			
			
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/project_zchuang/pub1.png">
                </div>
				
				<div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2022</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Fisher Information Guidance for Learned Time-of-Flight Imaging</h3>
                    <p class="publictions_indentation"> In this paper, we propose a Fisher-information guided framework to jointly optimize the coding functions (light modulation and sensor demodulation functions) and the reconstruction network of iToF imaging, with the supervision of the proposed discriminative fisher loss.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href=""
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
				
				
            <div class="publictions_text">
                    <p>IEEE International Conference on Computer Vision 2021</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Fast Light-field Disparity Estimation with Multi-disparity-scale Cost Aggregation</h3>
                    <p class="publictions_indentation"> In this paper, we design a lightweight disparity estimation model with physical-based multi-disparity-scale cost volume aggregation for fast disparity estimation.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/project_zchuang/pub1_Fast Light-field Disparity Estimation with Multi-disparity-scale Cost Aggregation.html"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
            
            <hr style="border: 1px dashed gray" />        
            
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/project_web_nisiqi/siqini.png">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2021</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Controlling the Rain from Removal to Rendering</h3>
                    <p class="publictions_indentation">This paper proposes to realize continuous control of rain
                        intensity bidirectionally,
                        from clear rain-free to downpour image with a single rain image as input, without changing the
                        scene-specific characteristics,
                        e.g. the direction, appearance and distribution of rain.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/project_web_nisiqi/Controlling the Rain from Removal to Rendering.html"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/project_web_sjzhao/sjzhao.png">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2021</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Distribution-aware Adaptive Multi-bit Quantization</h3>
                    <p class="publictions_indentation">In this paper, we explore the compression of deep neural networks
                        by quantizing the weights and activations into multi-bit binary networks (MBNs). A distribution-aware
                        multi-bit quantization (DMBQ) method that incorporates the distribution prior into the optimization of quantization is
                        proposed.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/project_web_sjzhao/distr.html"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p1.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Access 2020</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Influence of Beam Distribution on the Qualityof Compressed Sensing-Based THz Imaging</h3>
                    <p class="publictions_indentation">To achieve high sensitivity and resolution, newmeasurement
                        matrices correlating to the incident beam distribution are proposed and the simulation
                        resultsare demonstrated.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Influence of Beam Distribution on the Qualityof Compressed Sensing-Based THz Imaging.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p2.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Sensors Journal 2020</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Time-Delay-Integration Imaging Implemented With Single-Photon-Avalanche-Diode Linear Array</h3>
                    <p class="publictions_indentation">In this paper, we propose a novel kind of time
                        delay integration (TDI) image sensor based on single photon
                        avalanche diode (SPAD), i.e. TDI-SPAD.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Time-Delay-Integration Imaging Implemented.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>


            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p3.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Multispectral Video Acquisition Using Spectral Sweep Camera</h3>
                    <p class="publictions_indentation">To fully utilize the redundancies of multispectral
                        videos in the spatial, temporal and spectral dimensions, we propose a Complex Optical Flow
                        (COF) method that could extract the spatial and spectral signal variations between adjacent
                        spectral-sweep frames.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Multispectral video acquisition using spectral sweep camera.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p4.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE International Confernce on Computer Vision 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Enhancing Low Light Videos by Exploring High Sensitivity Camera Noise</h3>
                    <p class="publictions_indentation">We explore the physical origins of the practical high sensitivity
                        noise in digital cameras, and propose to enhance the low light videos based on the noise
                        model by using an LSTM-based neural network.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Enhancing Low Light Videos by Exploring Practical Camera Noise.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p5.jpg">
                </div>
                <div class="publictions_text">
                    <p>OSA, Nonlinear Optics 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Enhance imaging depth in wide-field two-photon microscopy
                        by extended detection and computational reconstruction</h3>
                    <p class="publictions_indentation">We propose the extended detection and computational
                        reconstruction technique, to extract signals from scattering photons and enhance imaging depths.
                    </p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Enhance imaging depth in wide-field two-photon microscopy.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p6.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Overcoming tissue scattering in wide-field deep imaging by extended detection and computational
                        reconstruction</h3>
                    <p class="publictions_indentation">In contrast to the spatial filtering based on confocal slit detection, here we propose the extended detection LTFM (ED-LTFM), the first wide-field two-photon imaging technique to extract signals from scattered photons and thus effectively extend the imaging depth.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Overcoming.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>


            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p7.jpg">
                </div>
                <div class="publictions_text">
                    <p>SPIE 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Video rate spectroscopy via Fourier-spectral-multiplexing</h3>
                    <p class="publictions_indentation">In this paper, we propose a video rate spectroscopy via
                        Fourier-spectral-multiplexing
                        (FSM-VRS) which exploits both spectral and spatial sparsity.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Video rate spectroscopy via Fourier-spectral-multiplexing.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p8.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Photonics Journal 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>High Fidelity Single-Pixel Imaging</h3>
                    <p class="publictions_indentation">Inspired by the fact that natural scenes exhibit unique degenerated structures in the low-dimensional subspace, we propose to take advantage of such local prior via convolutional sparse coding to implement high fidelity SPI.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/High Fidelity Single-Pixel Imaging.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p9.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Hyperspectral Imaging with Random Printed Mask</h3>
                    <p class="publictions_indentation">We
                        propose a simple and low-budget scheme to capture the
                        hyperspectral images with a random mask printed by the
                        consumer-level color printer.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Zhao_Hyperspectral_Imaging_With_Random_Printed_Mask_CVPR_2019_paper.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p10.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2019</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Spectral Reconstruction from Dispersive Blur: A Novel Light Efficient Spectral
                        Imager</h3>
                    <p class="publictions_indentation">We propose a basic theory for capturing multispectral information from a single dispersive-blurred image and an additional spectrum of an arbitrary point in the
                        scene</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Zhao_Spectral_Reconstruction_From_Dispersive_Blur_A_Novel_Light_Efficient_Spectral_CVPR_2019_paper.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p11.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2018</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Snapshot hyperspectral imaging via spectral
                        basis multiplexing in Fourier domain</h3>
                    <p class="publictions_indentation">In this paper, we propose a snapshot hyperspectral
                        imaging technique which exploits both spectral and spatial sparsity of natural scenes.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Snapshot hyperspectral imaging via spectral basis multiplexing in Fourier domain.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p12.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Transactions on Image Processing 2018</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Convolutional Sparse Coding for RGB+NIR Imaging</h3>
                    <p class="publictions_indentation">In this work,
                        we introduce a new approach to RGB+NIR image reconstruction
                        using learned convolutional sparse priors.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Convolutional Sparse Coding for RGB+NIR Imaging.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p13.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition Workshop 2018</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Resolution-Enhanced Lensless Color Shadow Imaging Microscopy Based on
                        Large Field-of-View Submicron-Pixel Imaging Sensors</h3>
                    <p class="publictions_indentation">We report a resolution-enhanced lensless color shadow
                        imaging microscopy system based on large field-of-view submicron-pixel imaging sensors.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Yang_Resolution-Enhanced_Lensless_Color_CVPR_2018_paper.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p14.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optica 2018</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Parallel cameras</h3>
                    <p class="publictions_indentation">This paper reviews the context of such cameras in the developing
                        field of computational imaging
                        and discusses how parallel architectures impact optical and electronic processing design.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Parallel cameras.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p15.jpg">
                </div>
                <div class="publictions_text">
                    <p>International Conference on Image Processing 2017</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Multispectral focal stack acquisition using a chromatic aberration enlarged camera</h3>
                    <p class="publictions_indentation">By using a delicately designed chromatic aberration
                        enlarged camera, the spectral-varying slices at different
                        depths of the scene can be easily captured.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/MULTISPECTRAL FOCAL STACK ACQUISITION USING A CHROMATIC ABERRATION ENLARGED CAMERA.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p16.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2017</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Heterogeneous camera array for multispectral light field imaging</h3>
                    <p class="publictions_indentation">In this paper, inspired by anaglyph theory (i.e. the ability of human eyes to synthesize colored stereo perception from color-complementary (such as red and cyan) views), we propose to capture the multispectral light field using multiple cameras with different wide band filters.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Heterogeneous camera array for multispectral light field imaging.pdf"
                            target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p17.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2016</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Variable Aperture Light Field Photography:
                        Overcoming the Diffraction-limited Spatio-angular Resolution Tradeoff</h3>
                    <p class="publictions_indentation">We propose a sequential, coded-aperture-style acquisition scheme that optimizes the resolution of a light field reconstructed from multiple
                        photographs captured from different perspectives and f-number settings.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Chang_Variable_Aperture_Light_CVPR_2016_paper.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>




            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p18.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Signal Processing Magazine 2016</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Computational Snapshot Multispectral Cameras</h3>
                    <p class="publictions_indentation">This article
                        presents an overview of these state-of-the-art
                        multispectral acquisition systems, with a particular
                        focus on snapshot multispectral capture, from
                        a signal processing perspective.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Computational Snapshot Multispectral Cameras.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>



            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p19.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Transactions on Circuits and Systems for Video Technology 2016</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Efficient Method for High-Quality Removal of Nonuniform Blur in the Wavelet Domain</h3>
                    <p class="publictions_indentation">This paper presents a novel nonuniform deblurring
                        approach, which defines the blur model and calculates regularized
                        nonuniform deconvolution in the wavelet domain to achieve
                        high efficiency and high accuracy.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Efficient Method for High-Quality Removal of.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p24.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2016</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Content-adaptive ghost imaging of
                        dynamic scenes</h3>
                    <p class="publictions_indentation">We propose a
                        content-adaptive computational ghost imaging approach to achieve high
                        reconstruction quality under a small number of measurements, and thus
                        achieve ghost imaging of dynamic scenes.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Content-adaptive ghost imaging of.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>



            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p20.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2015</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Blind Optical Aberration Correction by Exploring
                        Geometric and Visual Priors</h3>
                    <p class="publictions_indentation">We propose a computational approach for blind
                        aberration removal from a single image, by exploring various
                        geometric and visual priors.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Yue_Blind_Optical_Aberration_2015_CVPR_paper.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p21.jpg">
                </div>
                <div class="publictions_text">
                    <p>IEEE Computer Vision and Pattern Recognition 2015</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Efficient 3D Kernel Estimation for Non-uniform Camera Shake Removal
                        Using Perpendicular Camera System</h3>
                    <p class="publictions_indentation">We propose an acceleration method to
                        compute the 3D projection of 2D local blur kernels fast, and
                        then derive the 3D kernel by interpolating from a minimal
                        set of local blur kernels.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Yue_Efficient_3D_Kernel_2015_CVPR_paper.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p22.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2015</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Patch-primitive driven compressive
                        ghost imaging</h3>
                    <p class="publictions_indentation">Inspired by the fact that the natural image patches usually exhibit simple structures, and these structures share common primitives, we propose a patch-primitive driven reconstruction approach to raise the quality of ghost imaging.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Patch-primitive driven compressive.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>
    
            <hr style="border: 1px dashed gray" />
    
            <div class="box3">
                <div class="publictions_img">
                    <img src="./assert/p23.jpg">
                </div>
                <div class="publictions_text">
                    <p>Optics Express 2015</p>
                    <hr style="width:30px;margin-left: 0px;">
                    <h3>Gerchberg-Saxton-like ghost imaging</h3>
                    <p class="publictions_indentation">Correlation is widely used to reconstruct the object image in ghost imaging (GI). But it only offers a linear proportion of the signal-to-noise ratios (SNR) to the number of measurements. We develop a Gerchberg-Saxton-like technique for GI image reconstruction in this manuscript.</p>
                </div>
                <div class="publictions_more">
                    <p>
                        <a href="./assert/Gerchberg-Saxton-like ghost imaging.pdf" target="_blank">
                            &nbsp;ReadMore
                        </a>
                    </p>
                </div>
            </div>


​			
			<div class="box3">
	            <div class="publictions_img">
	                <img src="./assert/p24.png">
	            </div>
	            <div class="publictions_text">
	                <p>Optics Letters 2014</p>
	                <hr style="width:30px;margin-left: 0px;">
	                <h3>Robust and accurate transient light transport decomposition via convolutional sparse coding</h3>
	                <p class="publictions_indentation">Ultrafast sources and detectors have been used to record the time-resolved scattering of light propagating through macroscopic scenes. We demonstrate a method of convolutional sparse coding to decompose TLT into direct reflections, inter-reflections, and subsurface scattering. </p>
	            </div>
	            <div class="publictions_more">
	                <p>
	                    <a href="./assert/ultrafast_decomposing.pdf" target="_blank">
	                        &nbsp;ReadMore
	                    </a>
	                </p>
	            </div>
	        </div>


        </div>
    
    </div>

</body>

</html>